{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyN3AXvJt6T5RhbrY/qSajvO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Rapid-Fire Scenario Exposure** </br></br>\n","The Rapid-Fire Scenario Exposure module is designed to help users develop an intuition for distinguishing between “fair” and “unfair” outcomes. Using a set of examples from various disciplines, users can quickly assess the overall fairness of the situation. Fifteen examples are selected at random, each prompting the user to make a binary decision of FAIR or UNFAIR. Upon completion, the results of each question are tallied, and users are given an overall score. Users can replay the module as often as they like, and, like all modules, the underlying questions can be augmented and updated over time."],"metadata":{"id":"bnQGXGCebeuy"}},{"cell_type":"markdown","source":[],"metadata":{"id":"3Y9dK8Qzwtnp"}},{"cell_type":"code","source":["#@title pip install\n","!pip install ipywidgets"],"metadata":{"collapsed":true,"id":"yjt5v9rpov0b","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Imports\n","import random\n","import time\n","from IPython.display import display, clear_output\n","import ipywidgets as widgets\n","from ipywidgets import Button, VBox, HBox, HTML, Layout"],"metadata":{"id":"VrUEOiAsoxJm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Fairness Pattern Trainer\n","class FairnessPatternTrainer:\n","    def __init__(self):\n","        self.scenarios = [\n","            # UNFAIR scenarios\n","            {\n","                \"text\": \"Hiring algorithm: 80% accuracy for men, 60% accuracy for women, same qualifications\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Different accuracy rates across gender groups indicates systematic unfairness\"\n","            },\n","            {\n","                \"text\": \"Loan approval: 70% approval rate for zip code 10001, 30% for zip code 10002, similar income levels\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Geographic disparities with similar income suggest unfair redlining practices\"\n","            },\n","            {\n","                \"text\": \"Medical AI: Diagnostic accuracy 85% for light skin, 65% for dark skin\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Systematic accuracy differences by race indicate unfair training data representation\"\n","            },\n","            {\n","                \"text\": \"Resume screening: Rejects 80% of names like 'Jamal', accepts 60% of names like 'Brad', same qualifications\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Name-based discrimination indicates unfair racial bias in algorithm\"\n","            },\n","            {\n","                \"text\": \"Credit scoring: Lower scores for single mothers vs married couples with identical financial profiles\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Marital/family status creating different outcomes suggests unfair treatment\"\n","            },\n","            {\n","                \"text\": \"Voice assistant: Understands male voices 90% accuracy, female voices 70% accuracy\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Gender-based performance differences indicate unfair training bias\"\n","            },\n","            {\n","                \"text\": \"Facial recognition: 99% accuracy for ages 20-40, 75% accuracy for ages 65+\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Age-based accuracy disparities suggest unfair underrepresentation in training\"\n","            },\n","            {\n","                \"text\": \"Job matching: Suggests nursing jobs to women, engineering jobs to men with similar skills\",\n","                \"is_unfair\": True,\n","                \"explanation\": \"Gender stereotyping in job recommendations reflects unfair societal assumptions\"\n","            },\n","            # FAIR scenarios\n","            {\n","                \"text\": \"Medical AI: Higher diabetes risk scores for patients with family history vs those without\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Genetic factors are legitimate medical risk factors, making this fair treatment\"\n","            },\n","            {\n","                \"text\": \"Loan approval: Higher approval rates for borrowers with 800+ credit scores vs 600- credit scores\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Credit score is a legitimate factor for loan risk assessment, making this fair\"\n","            },\n","            {\n","                \"text\": \"Hiring algorithm: Prefers candidates with relevant work experience over those without\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Relevant experience is a legitimate job qualification, making this fair\"\n","            },\n","            {\n","                \"text\": \"Insurance pricing: Higher premiums for customers with multiple previous claims vs no claims\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Claims history is actuarially justified risk factor, making this fair\"\n","            },\n","            {\n","                \"text\": \"Academic admissions: Higher acceptance rates for students with better test scores and grades\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Academic performance metrics are relevant to educational outcomes, making this fair\"\n","            },\n","            {\n","                \"text\": \"Fraud detection: Flags unusual spending patterns as potential fraud\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Unusual patterns are legitimate fraud indicators, making this fair\"\n","            },\n","            {\n","                \"text\": \"Medical screening: Recommends mammograms for women over 50, not men\",\n","                \"is_unfair\": False,\n","                \"explanation\": \"Gender-specific medical recommendations based on biological differences are fair\"\n","            }\n","        ]\n","\n","        self.current_scenario = 0\n","        self.score = 0\n","        self.responses = []\n","        self.start_time = None\n","        self.response_times = []\n","\n","        random.shuffle(self.scenarios)\n","\n","        # Create widgets\n","        self.scenario_display = HTML(\n","            value=\"<h3>Fairness Pattern Recognition Training</h3>\",\n","            layout=Layout(text_align='center')\n","        )\n","\n","        self.unfair_button = Button(\n","            description='UNFAIR',\n","            button_style='danger',\n","            layout=Layout(width='200px', height='60px', margin='5px')\n","        )\n","\n","        self.fair_button = Button(\n","            description='FAIR',\n","            button_style='success',\n","            layout=Layout(width='200px', height='60px', margin='5px')\n","        )\n","\n","        self.next_button = Button(\n","            description='NEXT →',\n","            button_style='',\n","            layout=Layout(width='100px', height='30px', margin='10px')\n","        )\n","\n","        self.feedback_display = HTML(layout=Layout(text_align='center'))\n","        self.progress_display = HTML(layout=Layout(text_align='center'))\n","\n","        # Button clicks\n","        self.unfair_button.on_click(lambda b: self.handle_response(True))\n","        self.fair_button.on_click(lambda b: self.handle_response(False))\n","        self.next_button.on_click(lambda b: self.next_scenario())\n","\n","        # Centered layout\n","        answer_buttons = HBox(\n","            [self.unfair_button, self.fair_button],\n","            layout=Layout(justify_content='center')\n","        )\n","\n","        next_button_box = HBox(\n","            [self.next_button],\n","            layout=Layout(justify_content='center')\n","        )\n","\n","        self.widget = VBox([\n","            self.scenario_display,\n","            answer_buttons,\n","            self.feedback_display,\n","            next_button_box,\n","            self.progress_display\n","        ])\n","\n","    def start_training(self, num_scenarios=10):\n","        self.scenarios = self.scenarios[:num_scenarios]\n","        self.current_scenario = 0\n","        self.score = 0\n","        self.responses = []\n","        self.response_times = []\n","        self.show_scenario()\n","        return self.widget\n","\n","    def show_scenario(self):\n","        if self.current_scenario >= len(self.scenarios):\n","            self.show_results()\n","            return\n","\n","        scenario = self.scenarios[self.current_scenario]\n","        self.start_time = time.time()\n","\n","        self.scenario_display.value = f\"\"\"\n","        <div style='border: 2px solid #ddd; padding: 20px; border-radius: 10px; background: #f9f9f9; text-align: center;'>\n","            <h3>Question {self.current_scenario + 1} of {len(self.scenarios)}</h3>\n","            <p style='font-size: 16px; line-height: 1.5;'><strong>{scenario['text']}</strong></p>\n","            <p style='color: #666;'><em>Is this FAIR or UNFAIR?</em></p>\n","        </div>\n","        \"\"\"\n","        self.feedback_display.value = \"\"\n","        self.update_progress()\n","\n","    def handle_response(self, user_says_unfair):\n","        if self.start_time is None:\n","            return\n","\n","        response_time = time.time() - self.start_time\n","        scenario = self.scenarios[self.current_scenario]\n","        correct = user_says_unfair == scenario['is_unfair']\n","\n","        if correct:\n","            self.score += 1\n","\n","        self.responses.append({\n","            'correct': correct,\n","            'response_time': response_time\n","        })\n","        self.response_times.append(response_time)\n","\n","        # Show feedback\n","        color = \"green\" if correct else \"red\"\n","        text = \"✓ Correct!\" if correct else \"✗ Incorrect\"\n","\n","        self.feedback_display.value = f\"\"\"\n","        <div style='border: 2px solid {color}; padding: 15px; border-radius: 8px; margin: 10px 0; text-align: center;'>\n","            <h4 style='color: {color}; margin: 0;'>{text}</h4>\n","            <p><strong>Explanation:</strong> {scenario['explanation']}</p>\n","            <p><em>Response time: {response_time:.1f} seconds</em></p>\n","        </div>\n","        \"\"\"\n","\n","        self.start_time = None\n","        self.update_progress()\n","\n","    def next_scenario(self):\n","        self.current_scenario += 1\n","        self.show_scenario()\n","\n","    def update_progress(self):\n","        if len(self.responses) > 0:\n","            accuracy = self.score / len(self.responses) * 100\n","            avg_time = sum(self.response_times) / len(self.response_times)\n","        else:\n","            accuracy = avg_time = 0\n","\n","        self.progress_display.value = f\"\"\"\n","        <div style='background: #e8f4fd; padding: 10px; border-radius: 5px; text-align: center;'>\n","            <strong>Progress:</strong> {len(self.responses)}/{len(self.scenarios)} |\n","            <strong>Accuracy:</strong> {accuracy:.1f}% |\n","            <strong>Avg Time:</strong> {avg_time:.1f}s\n","        </div>\n","        \"\"\"\n","\n","    def show_results(self):\n","        accuracy = self.score / len(self.scenarios) * 100\n","        avg_time = sum(self.response_times) / len(self.response_times)\n","\n","        self.scenario_display.value = f\"\"\"\n","        <div style='border: 3px solid #4CAF50; padding: 25px; border-radius: 15px; background: #f8fff8; text-align: center;'>\n","            <h2 style='color: #4CAF50;'>Training Complete! 🎯</h2>\n","            <h3>Results:</h3>\n","            <ul style='list-style: none; padding: 0;'>\n","                <li><strong>Accuracy:</strong> {accuracy:.1f}% ({self.score}/{len(self.scenarios)})</li>\n","                <li><strong>Average Time:</strong> {avg_time:.1f} seconds</li>\n","            </ul>\n","        </div>\n","        \"\"\"\n","\n","        # Hide buttons\n","        self.unfair_button.layout.display = 'none'\n","        self.fair_button.layout.display = 'none'\n","        self.next_button.layout.display = 'none'\n","        self.feedback_display.value = \"\""],"metadata":{"id":"T8eFM6IVym0f","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Start Simulator\n","# Start the fairness pattern recognition training\n","trainer = FairnessPatternTrainer()\n","widget = trainer.start_training(15)  # Practice with 15 scenarios\n","display(widget)"],"metadata":{"id":"eYt-dV_OpEcW","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V68d_YQDrW4F"},"execution_count":null,"outputs":[]}]}
